\chapter{Introducción específica} % Main chapter title

\label{Chapter2}

%----------------------------------------------------------------------------------------
%	2.1 ENFOQUE DEL PROBLEMA
%----------------------------------------------------------------------------------------
El objetivo de este capítulo es proporcionar una base teórica sólida sobre las herramientas y 
métodos utilizados en el desarrollo de este trabajo. En particular,  se presentan las principales 
etapas de trabajo, se explican los conceptos elementales de los algoritmos de clasificación binaria 
y se exploran los fundamentos del perceptrón multicapa.

\section{Enfoque del problema}
\label{sec:Enfoque del problema}

El presente trabajo se estructura en torno a tres etapas principales, las cuales se 
encuentran ilustradas en la figura \ref{fig:Etapas de trabajo}.


\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./Figures/Etapas de trabajo.jpg}
	\caption{Representación esquemática de las etapas del trabajo.}\label{fig:Etapas de trabajo}
\end{figure}

Para comenzar, se llevó a cabo la adquisición de datos. 
Esta etapa fue realizada en colaboración con el servicio de cardiología del Hospital Alemán. 
Para ello, se recopiló información proveniente de presurometrías realizadas a pacientes 
hipertensos a partir del año 2013. Además, se efectuó un análisis exhaustivo de la historia 
clínica de cada paciente con el objetivo de identificar la ocurrencia de eventos cardiovasculares 
adversos mayores. De esta manera, se logró completar el \textit{dataset} con la variable a predecir (MACE) 
para cada paciente. Asimismo, se enriqueció el conjunto de datos con información clínica adicional 
con el fin de contar con variables explicativas más amplias para abordar el problema de investigación.

A continuación, se efectuó una etapa de preprocesamiento. En primer lugar, se procedió a realizar 
una limpieza de los datos con el propósito de seleccionar las variables más representativas del 
problema. Este proceso de selección permitió eliminar datos redundantes, ruidosos o de poca 
utilidad para el análisis posterior. También, se realizó un análisis exploratorio de datos 
para comprender de manera más profunda las características y patrones presentes en el \textit{dataset}. 
Esto proporcionó una visión más completa y significativa del conjunto de datos, permitiendo 
así una mejor comprensión de la naturaleza del problema y orientando la toma de decisiones 
posteriores en el desarrollo de este trabajo.

Por último, se procedió al diseñó y entrenamiento de dos modelos de clasificación utilizando 
redes neuronales. El primer modelo se construyó exclusivamente con los datos de presurometrías, 
mientras que el segundo también incluyó los datos clínicos. El propósito 
de esta estrategia fue analizar y comparar el rendimiento de los dos modelos y evaluar si los 
datos de MAPA tienen un sustento suficiente para predecir la variable objetivo MACE. De esta 
manera, se buscó determinar si la inclusión de información clínica adicional contribuye a 
mejorar las métricas de desempeño, y si tiene implicancias 
clínicas relevantes para el seguimiento de los pacientes.

%----------------------------------------------------------------------------------------
%	2.2 ALGORITMOS DE CLASIFICACION
%----------------------------------------------------------------------------------------
\section{Algoritmos de clasificación}
\label{sec:Algoritmos de clasificación}

En esta sección se presentan los fundamentos de los modelos de clasificación, junto con las 
estrategias utilizadas para abordar el desbalance de clases, con especial énfasis en la técnica SMOTE. 
Además, se exploran las métricas utilizadas para evaluar el desempeño de los modelos desarrollados.

%----------------------------------------------------------------------------------------
% 2.2.1 Fundamentos de los modelos de clasificación

\subsection{Fundamentos de los modelos de clasificación}
Un algoritmo de aprendizaje automático es una herramienta que permite resolver tareas  
que suelen ser complejas de abordar para los seres humanos. La principal ventaja del \emph{machine 
learning} (ML) es su capacidad de aprender de los datos y extraer información relevante de 
estos. Las tareas de ML se describen en términos de cómo deben procesar un ejemplo, que se 
compone de una colección de características cuantitativas o \emph{features} que se miden de un objeto 
o evento que se desea procesar. En general, se representa un ejemplo como un vector $ x\in\mathbb{R}^n $,
donde cada entrada $x_{i}$ del vector corresponde a una característica del objeto 
o evento en cuestión. De esta manera, el algoritmo de aprendizaje de máquina es capaz de 
analizar los datos y extraer patrones que permiten tomar decisiones o realizar predicciones 
precisas \citep{CITE:35}.

En el campo del aprendizaje automático, los modelos de clasificación desempeñan un papel fundamental 
\citep{CITE:32}. Estos modelos se encargan de asignar etiquetas discretas o categorías a ejemplos 
específicos según sus características \citep{CITE:33}. Dependiendo del enfoque utilizado durante el 
entrenamiento, los modelos pueden ser de dos tipos: supervisados o no supervisados \citep{CITE:35}.

En un modelo de clasificación no supervisado, las etiquetas no se proporcionan en el conjunto de 
datos de entrenamiento \citep{CITE:34}. En lugar de ello, el algoritmo busca patrones y estructuras 
en los datos sin la guía explícita de las etiquetas. Como resultado, el objetivo es agrupar las instancias en 
clases basadas en similitudes \citep{CITE:33}.

Por otro lado, en un modelo de clasificación supervisado se proporciona al algoritmo un \emph{dataset} de 
entrenamiento que incluye tanto las características de las instancias como las etiquetas correspondientes 
\citep{CITE:33}. El modelo utiliza esta información para aprender a asociar las \emph{features} con las 
etiquetas, lo que le permite clasificar nuevas instancias de manera precisa. Algunos ejemplos de algoritmos 
supervisados ampliamente utilizados son los árboles de decisión, las máquinas de vectores de soporte y 
las redes neuronales \citep{CITE:34}. En este trabajo en particular, se empleó un modelo de clasificación 
supervisado basado en redes neuronales con el propósito de predecir MACE. Es importante señalar que se trata
de una clasificación binaria puesto que la variable \emph{target} tiene dos posibles valores: ausencia ("0") o 
presencia ("1") de eventos cardiovasculares adversos mayores.

%----------------------------------------------------------------------------------------
% 2.2.2 Estrategias para tratar el desbalance de clases
\subsection{Estrategias para tratar el desbalance de clases}

Un conjunto de datos se considera desbalanceado cuando presenta una proporción significativamente mayor 
de observaciones pertenecientes a una clase en comparación con la otra. Este desequilibrio puede tener 
un impacto considerable en el rendimiento de los modelos de aprendizaje automático. En el caso específico 
de una red neuronal entrenada con un \emph{dataset} desbalanceado, es probable que encuentre dificultades 
para discriminar de manera adecuada entre las diferentes clases. En otras palabras, el desequilibrio de 
clases crea un sesgo en el cual el modelo tiende a predecir la clase mayoritaria, lo que dificulta la 
correcta clasificación de los ejemplos pertenecientes a la clase minoritaria \citep{CITE:36} \citep{CITE:37}. 

Abordar el desequilibrio se convierte en un desafío crucial en la tarea de modelado y actualmente existen 
dos enfoques principales con este fin. El primero consiste en asignar diferentes pesos a los ejemplos de entrenamiento, 
mientras que el segundo implica realizar un remuestreo del conjunto de datos original. Es posible crear 
un nuevo muestreo del \emph{dataset} efectuando un sobremuestreo de la clase minoritaria y/o un submuestreo 
de la clase mayoritaria. El submuestreo implica una reducción del número de instancias de la clase mayoritaria, 
lo cual puede resultar en la pérdida de información valiosa que sea representativa de la distribución de los 
datos. Por otra parte, el sobremuestreo suele incluir réplicas de ejemplos de la clase minoritaria, lo cual 
puede generar un sobreajuste. Cabe señalar que un modelo sobreajustado concede predicciones 
muy precisas para el conjunto de entrenamiento pero no logra generalizar adecuadamente cuando se presentan 
nuevos datos \citep{CITE:37}. 

Para mitigar las desventajas mencionadas anteriormente, Nitesh Chawla \emph{et al.} \citep{CITE:37} 
introducen una nueva técnica que implica una forma especial 
de sobremuestrear la clase minoritaria. El algoritmo 
\emph{Synthetic Minority Over-sampling Technique} (SMOTE) implica la creación de muestras sintéticas de 
la clase minoritaria. Se expone una representación gráfica del algoritmo en la figura \ref{fig:SMOTE}. 
En primer lugar, el método escoge un ejemplo de la clase minoritaria al azar y encuentra a sus $k$ vecinos 
más cercanos. Luego, se selecciona uno de los $k$ vecinos más cercanos y se crea una conexión mediante 
un segmento de línea en el espacio de características con la muestra elegida al azar. Finalmente, se crea 
una instancia sintética en un punto aleatorio entre los dos ejemplos. Este procedimiento se repite para
todas las muestras minoritarias \citep{CITE:38}. 

\begin{figure}[h!]
	\centering
	\subcaptionbox{SMOTE comienza con un conjunto de ejemplos positivos (puntos verdes) y negativos (puntos azules).}%
  	[0.3\linewidth]{\includegraphics[height=5cm]{./Figures/SMOTE_a.jpg}}\label{fig:SMOTEa}
	\hspace{1em}
	\subcaptionbox{Se selecciona un ejemplo positivo (punto con borde negro) y sus $k$ vecinos más cercanos entre los positivos (puntos amarillos, con $k = 3$).}
	[0.3\linewidth]{\includegraphics[height=5cm]{./Figures/SMOTE_b.jpg}}\label{fig:SMOTEb}
	\hspace{1em}
	\subcaptionbox{Para cada $k$ vecino más cercano se agrega un nuevo ejemplo sintético (puntos rojos) a lo largo de la línea recta que los conecta con el ejemplo positivo.}
	[0.3\linewidth]{\includegraphics[height=5cm]{./Figures/SMOTE_c.jpg}}
	\caption{Representación esquematica del algoritmo SMOTE\protect\footnotemark.}\label{fig:SMOTEc}
	   \label{fig:SMOTE}
\end{figure}


En suma, SMOTE permite generar ejemplos sintéticos que sean relativamente cercanos en el espacio de 
características con respecto a las muestras existentes de la clase minoritaria. Además, las muestras 
pueden crearse en la cantidad que sea requerida. Por lo tanto, en escenarios donde el conjunto de 
datos no solo está desbalanceado sino que también presenta una escasez de muestras, la aplicación 
de SMOTE resulta particularmente efectiva \citep{CITE:37} \citep{CITE:38}.


%----------------------------------------------------------------------------------------
% 2.2.3 Métricas de evaluación en modelos de clasificación
\subsection{Evaluación de modelos de clasificación}

% el footnote text es de la imagen de smote, pero si lo ponia mas arriba lo corria en la pagina anterior
\footnotetext{Imagen adaptada de Schubach, Max; Re, Matteo; Robinson, Peter y Valentini, Giorgio. (2017). Imbalance-Aware Machine Learning for Predicting Rare and Common Disease-Associated Non-Coding Variants. Scientific Reports. 7. 10.1038/s41598-017-03011-5.}

Para evaluar el desempeño de un modelo de clasificación binaria se suele emplear una matriz de confusión. 
Esta matriz se ilustra en la figura \ref{fig:MatrizConfusion}, donde las columnas representan la clase 
predicha y las filas corresponden a las clases reales \citep{CITE:44}. 
A partir de esta tabla, se definen cuatro indicadores:

\begin{itemize}
	\item Verdaderos positivos (TP, por sus siglas en inglés): asignaciones positivas correctas.
	\item Verdaderos negativos (TN, por sus siglas en inglés): asignaciones negativas correctas.
\item Falsos positivos (FP, por sus siglas en inglés): asignaciones positivas incorrectas, es decir que
indican la presencia de una condición cuando la misma en realidad no está presente.
\item Falsos negativos (FN, por sus siglas en inglés): asignaciones negativas incorrectas, lo que significa
que indican la ausencia de una condición cuando en realidad está presente.
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{./Figures/MatrizConfusion.jpg}
	\caption{Matriz de confusión\protect\footnotemark.}\label{fig:MatrizConfusion}
\end{figure}


En el ámbito médico, el falso negativo puede ocasionar las consecuencias más graves para la salud del 
paciente. En este trabajo en particular, implica el riesgo de no tomar las medidas necesarias para un 
tratamiento adecuado, lo cual puede incurrir en que el paciente experimente un evento cardiovascular 
adverso mayor. En consecuencia, es de gran importancia minimizar la tasa de falsos negativos al máximo, 
aún si esto implica un aumento de falsos positivos. Si bien este incremento puede implicar la necesidad de 
destinar más recursos médicos para realizar pruebas adicionales o tratamientos innecesarios, se garantiza 
que menos casos sean pasados por alto \citep{CITE:40}.

\filbreak

% el footnote text es de la imagen de MatrizConfusion, pero si lo ponia mas arriba lo corria en la pagina anterior
\footnotetext{Imagen adaptada de Portilla, Jose. 2018. Data Science and Machine Learning Bootcamp with R. https://www.udemy.com/data-science-and-machine-learning-bootcamp-with-r/.}

A partir de los valores de TP, TN, FP y FN se definen diferentes métricas para evaluar el desempeño de 
un modelo de clasificación. A continuación, se presentan las que fueron utilizadas en este trabajo.

\subsubsection{\emph{Precision}}
La presición o \emph{precision} es una métrica que permite conocer la proporción de ejemplos clasificados 
correctamente como positivos sobre el total de ejemplos clasificados como positivos. Una alta precisión 
indica que el modelo tiene una baja tasa de falsos positivos y clasifica correctamente la mayoría de las 
instancias positivas. La expresión matemática que describe este comportamiento es la siguiente:

\begin{equation}
	\label{eq:precision}
	Precision = \frac{TP}{TP + FP}
\end{equation}


\subsubsection{\emph{Recall}}
La sensibilidad, \emph{recall} o tasa positiva real (TPR) es una métrica que mide la proporción de ejemplos 
clasificados correctamente como positivos en relación con el total de ejemplos positivos. Por lo tanto, se 
mide la capacidad de identificar la mayoría de las muestras positivas presentes. La ecuación que describe 
a la sensibilidad es:

\begin{equation}
	\label{eq:recall}
	Recall = \frac{TP}{TP + FN}
\end{equation}


\subsubsection{\emph{F1 score}}
El \emph{f1 score} representa la media armónica entre \emph{precision} y \emph{recall}. Dado que tiene 
en cuenta tanto a los FP cómo los FN, se emplea para evaluar un modelo cuando el conjunto de datos es 
desequilibrado. La fórmula matemática que describe este comportamiento es la siguiente:

\begin{equation}
	\label{eq:f1score}
	F1\,score = \frac{2}{\nicefrac{1}{Precision} + \nicefrac{1}{Recall}} = 2\cdot\frac{Recall \cdot Precision}{Recall + Precision}
\end{equation}

\subsubsection{\emph{Accuracy}}
La exactitud o \emph{accuracy} es una métrica que mide la proporción de muestras clasificadas correctamente 
sobre el total de muestras evaluadas y se describe matemáticamente como:

\begin{equation}
	\label{eq:accuracy}
	Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\subsubsection{\emph{Specificity}}
La especificidad, \emph{specificity} o tasa negativa real (TNR) se define como la proporción de falsos positivos 
sobre el total de negativos reales. Es una métrica exactamente opuesta a la sensibilidad y esta dada por:

\begin{equation}
	\label{eq:specificity}
	Specificity = \frac{TN}{TN + FP}
\end{equation}


\subsubsection{Curva ROC y AUC}
La curva ROC es una representación gráfica que muestra la tasa de verdaderos positivos (sensibilidad)
en función de la tasa de falsos positivos (1 - especificidad) a medida que se varía el umbral de 
clasificación. Si bien puede ser de utilidad visualizar la curva ROC, en muchas casos la información 
puede resumirse en la métrica AUC (acrónimo de \emph{Area Under the Curve}), que mide el área bajo la curva 
ROC. En general, cuanto más alto sea el AUC, mejor es el desempeño del clasificador \citep{CITE:37} \citep{CITE:44}. 

En la figura \ref{fig:ROC_a}, se puede observar un clasificador ideal en el cual las curvas de TP y TN no se 
superponen en absoluto, lo que resulta en un AUC igual a 1. Por el contrario, en la figura \ref{fig:ROC_c} 
se muestra un clasificador de predicción aleatoria, donde la curva ROC es una línea recta con una pendiente unitaria. 
En este caso, las curvas de TP y TN se superponen por completo, lo que da como resultado un AUC de 0.5. 
En la figura \ref{fig:ROC_b} se observa un caso intermedio en el que hay cierta superposición entre las curvas 
de TP y TN. En general, la mayoría de los modelos de clasificación binaria tienen un AUC entre 0.5 y 1. Es poco 
común encontrar un clasificador con un AUC menor que 0.5, ya que esto indicaría que las predicciones están invertidas \citep{CITE:44}.

\begin{figure}[h!]
	\centering
	\subcaptionbox{Clasificador perfecto.\label{fig:ROC_a}}%
  	[0.3\linewidth]{\includegraphics[height=8cm]{./Figures/ROC_a.jpg}}
	\hspace{1em}
	\subcaptionbox{Clasificador con buen \\poder predictivo.\label{fig:ROC_b}}
	[0.3\linewidth]{\includegraphics[height=8cm]{./Figures/ROC_b.jpg}}
	\hspace{1em}
	\subcaptionbox{Clasificador sin poder predictivo.\label{fig:ROC_c}}
	[0.3\linewidth]{\includegraphics[height=8cm]{./Figures/ROC_c.jpg}}
	\caption{Representación gráfica de la curva ROC y las distribuciones de TP y TN\protect\footnotemark.}
\end{figure}

La curva ROC y, en particular, el AUC son métricas ampliamente utilizadas en el ámbito clínico. 
Esto se debe a su capacidad para evaluar la habilidad de un modelo en la discriminación entre clases 
positivas y negativas. Esto resulta fundamental en la detección de enfermedades, diagnósticos médicos 
y evaluación de la efectividad de tratamientos.

%----------------------------------------------------------------------------------------
%	2.3 PERCEPTRÓN MULTICAPA
%----------------------------------------------------------------------------------------
\filbreak
\section{Perceptrón multicapa}
\label{sec:Perceptrón multicapa}

% el footnote text es de la imagen de ROC, pero si lo ponia mas arriba lo corria en la pagina anterior
\footnotetext{Imagen adaptada de Glen, S. (2019). ROC Curve Explained in One Picture. Data Science Central. https://www.datasciencecentral.com/roc-curve-explained-in-one-picture/.}

Las redes neuronales artificiales (RNA), propuestas inicialmente por McCulloch y Pitts en 1943 
\citep{CITE:41}, son modelos computacionales que se inspiran en el funcionamiento del cerebro 
humano. Si bien existen diversos tipos de RNA, esta sección se centra en los perceptrones 
multicapa, puesto que es la red empleada en este trabajo. En particular, se abordan varios 
aspectos teóricos clave relacionados con los perceptrones multicapa, incluyendo los bloques 
fundamentales que componen esta red, el algoritmo de entrenamiento, la validación del modelo, 
los hiperparámetros y los optimizadores.

%----------------------------------------------------------------------------------------
% 2.3.1 Perceptrón
\subsection{Perceptrón}
Un perceptrón, también conocido como neurona artificial o nodo, es el bloque fundamental de las 
RNA y fue propuesto por Frank Rosenblatt en 1957 \citep{CITE:43}. En la figura \ref{fig:Perceptron} se puede observar 
cómo un perceptrón recibe $n$ señales de entrada $x = (x_1, x_2, …, x_n)$, las cuales se multiplican 
por un peso $W = (w_1, w_2, …, w_n)$. Este comportamiento es análogo a la manera en que los 
pesos sinápticos influyen en las neuronas biológicas, ya que algunas entradas tienen mayor relevancia 
que otras. Por este motivo, las entradas se combinan como una suma ponderada por sus pesos 
($\sum_{i=1}^{n} W_i \cdot x_i$) y se añade un término independiente conocido como \emph{bias} o 
sesgo, con el fin de otorgar flexibilidad en la modelización de patrones complejos. 
Posteriormente, se aplica una transformación no lineal mediante una función de activación $g$, 
la cual determina la salida $\hat{y}$ del perceptrón \citep{CITE:35} \citep{CITE:42}. 
La descripción matemática de este comportamiento se expresa de la siguiente manera: 

\begin{equation}\label{eq:perceptron}
\begin{split}
	&\hat{y} = g(z) = g( \sum_{i=1}^{n} W_{i} \cdot x_{i} + b) \\
				&\hat{y} = g(x_1 \cdot w_1 + x_1 \cdot w_1 + … + x_n \cdot w_n + b)
\end{split}
\end{equation}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./Figures/Perceptron.jpg}
	\caption{Representación de un perceptrón\protect\footnotemark.}
	\label{fig:Perceptron}
\end{figure}


\footnotetext{Imagen adaptada de Hange, A. (2021). Target Prediction using Single-layer Perceptron and Multilayer Perceptron. Nerd For Tech. https://medium.com/nerd-for-tech/flux-prediction-using-single-layer-perceptron-and-multilayer-perceptron-cf82c1341c33/.}

%----------------------------------------------------------------------------------------
% 2.3.2 Arquitectura del perceptrón multicapa
\subsection{Arquitectura del perceptrón multicapa}

Un perceptrón multicapa (MLP, por sus siglas en inglés), también conocido como \emph{feedforward neural network} es 
una arquitectura de RNA ampliamente utilizada en el campo del aprendizaje profundo. Como se aprecia en la figura \ref{fig:MLP}, 
un MLP está compuesto por tres capas: capa de entrada o \emph{input layer}, capa oculta 
o \emph{hidden layer} y capa de salida o \emph{output layer}. 
A su vez, cada capa está formada por neuronas artificiales. La arquitectura del MLP es conocida como \emph{feedforward} 
puesto que la información siempre fluye desde la capa de entrada hacia la capa de salida a través de las capas ocultas, 
sin conexiones de retroalimentación. Cuando una RNA tiene dos o más capas ocultas, se lo conoce como una red neuronal 
profunda o \emph{deep neural network} (DNN) \citep{CITE:35} \citep{CITE:44}. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./Figures/MLP.jpg}
	\caption{Representación de un perceptrón multicapa \\ \emph{fully connected}\protect\footnotemark.}
	\label{fig:MLP}
\end{figure}

\filbreak
Por otro lado, el número de neuronas en la capa de entrada está definido por la cantidad de variables independientes 
del modelo, mientras que el número de nodos de la salida es la cantidad de variables dependientes. Además, el número de 
capas ocultas y su cantidad de neuronas dependen de la complejidad del modelo en cuestión, y son parámetros importantes 
a tener en cuenta durante el desarrollo de la red \citep{CITE:42}.

La configuración del perceptrón multicapa de la figura \ref{fig:MLP} se conoce como \emph{fully connected}, ya que todos 
los nodos de una capa están conectados con todos los nodos de las capas adyacentes. Sin embargo, existen otros tipos de 
capas que poseen diferentes estructuras de conexión. Por ejemplo, las de abandono o \emph{dropout} introducen la omisión de 
algunos nodos durante el entrenamiento de forma aleatoria para reducir el sobreajuste \citep{CITE:44} \citep{CITE:45}.

En general, la función de activación comúnmente empleada en las capas ocultas es la unidad lineal rectificada (ReLU, 
por sus siglas en inglés). La elección de ReLU se basa en dos ventajas principales: su implementación es rápida y no 
tiene un valor máximo de salida. En consecuencia, se evitan ciertos problemas durante el descenso del gradiente. En la 
ecuación \ref{eq:relu}, se observa que si el valor de entrada $z$ es negativo, la función retorna un 0; de lo contrario, 
devuelve el valor de $z$ \citep{CITE:44}. 

\footnotetext{Imagen adaptada de Hange, A. (2021). Target Prediction using Single-layer Perceptron and Multilayer Perceptron. Nerd For Tech. https://medium.com/nerd-for-tech/flux-prediction-using-single-layer-perceptron-and-multilayer-perceptron-cf82c1341c33/.}

\begin{equation}
	\label{eq:relu}
	ReLU(z) = max(0, z)
\end{equation}

Por otro lado, en la capa de salida de un modelo de clasificación binaria, es común utilizar la función sigmoide o 
\emph{sigmoid}. Esta función, definida en la ecuación \ref{eq:sigmoid}, toma valores reales como entrada y genera 
valores de salida en el rango de 0 a 1. Así, la función sigmoide es útil para predecir la probabilidad de una 
variable binaria \citep{CITE:44}. 

\begin{equation}
	\label{eq:sigmoid}
	\sigma(z) = \frac{1} {1 + e^{-z}}
\end{equation}


%----------------------------------------------------------------------------------------
% 2.3.3 Algoritmo de entrenamiento
\subsection{Algoritmo de entrenamiento}
El perceptrón multicapa se entrena con el fin de minimizar el error entre la salida deseada $y$ y 
la salida computada por el modelo $\hat{y}$ empleando una función de pérdida o \emph{loss function}. 
En el caso de problemas de clasificación binaria, se utiliza una función llamada 
\emph{binary cross entropy} (BCE), que se define como:

\begin{equation}
	\label{eq:BCE}
	\mathcal{L} = -\frac{1}{N} \sum_{i=1}^Ny_{i}\cdot\log(\hat{y_{i}}) + (1 - y_{i})\cdot\log(1 - \hat{y_{i}})
\end{equation}

Como resultado, cuando la salida verdadera es $y_{i} = 1$, la probabilidad de clasificarlo como 
1 es  $\hat{y_{i}}$, lo que hace que el segundo término se anule. Por el contrario, cuando la 
salida verdadera es $y_{i} = 0$, la probabilidad de clasificarlo como 1 es  $1 - \hat{y_{i}}$, 
lo que hace que se cancele el primer término. De esta forma, al aplicar el logaritmo, la BCE 
penaliza en mayor medida cuando el modelo clasifica incorrectamente con alta confianza \citep{CITE:46}. 
En consecuencia, si la red produce una respuesta equivocada, los pesos se actualizan para minimizar el error. 
Esto conduce a una reducción de los errores y aumenta la probabilidad de que las salidas futuras de la red 
sean correctas. En la práctica, el algoritmo de aprendizaje de un MLP involucra una etapa de propagación 
hacia adelante (\emph{forward propagation}) seguida de una etapa de propagación hacia atrás (\emph{backward propagation} 
o \emph{backpropagation}) \citep{CITE:35}. A continuación, se describen brevemente estas etapas.

\subsubsection{Propagación hacia adelante}
La fase de propagación hacia adelante implica el flujo de información desde la capa de entrada hacia la de 
salida de la red neuronal, con el objetivo de realizar una predicción. La salida de la n-ésima capa se 
define en la ecuación \ref{eq:forward}, donde $h^{(n)}$ es la salida, $g^{(n)}$ es la función de activación, $W^{(n)}$ 
es la matriz de pesos y $b^{(n)}$ es el vector de sesgos \citep{CITE:35} \citep{CITE:44}.

\begin{equation}
	\label{eq:forward}
	h^{(n)} = g^{(n)} (W^{(n)T} \cdot h^{(n-1)} + b^{(n)})
\end{equation}

El algoritmo~\ref{alg:forward} describe el proceso de \emph{forward propagation} en una red neuronal de profundidad $n$. 
Luego de calcular la predicción $\hat{y}$, se calcula la función de costo total $J$ durante la fase de entrenamiento. 
Esta se define como la suma de la función de pérdida $\mathcal{L}$ y un término de regularización $\lambda \Omega(w)$.

\subsubsection{Retropropagación}

Durante muchos años, los investigadores se enfrentaron al desafío de encontrar una forma 
efectiva de entrenar a los perceptrones multicapa sin éxito. Sin embargo, en 1986, D. E. 
Rumelhart \emph{et al.} publicaron un artículo revolucionario que introdujo el método 
de \emph{backpropagation} \citep{CITE:47}. La fase de retropropagación se describe en el 
algoritmo~\ref{alg:backpropagation}. Esta implica el cálculo del gradiente de la función de 
costo respecto a todos los parámetros entrenables empleando la regla de la cadena. 
Luego, este gradiente se propaga desde la salida hacia la entrada de la red neuronal \citep{CITE:35} \citep{CITE:42} \citep{CITE:44}.

\floatname{algorithm}{Algoritmo}
\begin{algorithm}
	\caption{Propagación hacia adelante de una RNA con $n$ capas.}
	\label{alg:forward}
	\begin{algorithmic}
		\Require $W^{(i)}, i \in 1, \ldots, n$ 
		\Require $b^{(i)}, i \in 1, \ldots, n$ 
		\Require $x$ 
		\Require $y$ 
		\State $h^{(1)} \gets x$
		\For{$m \gets 1, \ldots, n$}
		\State $a^{(m)} \gets W^{(m)T}h^{(m-1)} + b^{(m)} $
		\State $h^{(m)} \gets g(a^{(m)})$
		\EndFor
		\State $\hat{y} \gets h^{(n)}$
		\State $J \gets \mathcal{L}(\hat{y}, y) + \lambda \Omega(w)$ \Comment{\small Si es fase de entrenamiento.}
	\end{algorithmic}
\end{algorithm}


\begin{algorithm}[H]
	\caption{Propagación hacia atrás de una RNA con $n$ capas.}
	\label{alg:backpropagation}
		\begin{algorithmic}
		\State $g \gets \nabla_{\hat{y}} J = \nabla_{\hat{y}} \mathcal{L}(\hat{y}, y)$ \Comment{\small Cálculo del gradiente en la capa de salida.}
		\For{$m \gets n, n-1, \ldots, 1$}
		\State $g \gets \nabla_{a^{(m)}} J = g \odot f'(a^{(m)})$ \Comment{Actualiza el gradiente $g$.}
		\State $\nabla_{b^{(m)}} J = g + \lambda \nabla_{b^{(m)}} \Omega(w)$ \Comment{\small Cálculo del gradiente respecto a $b^{(m)}$.}
		\State $\nabla_{W^{(m)}} J = g h^{(m-1)} + \lambda \nabla_{W^{(m)}} \Omega(w)$ \Comment{\small Cálculo del gradiente respecto a $W^{(m)}$.}
		\State $g \gets \nabla_{h^{(m-1)}} J = W^{(m)T}g$ \Comment{\small Propagación del gradiente.}
		\EndFor
	\end{algorithmic}
\end{algorithm}
%----------------------------------------------------------------------------------------
% 2.3.4 Validación del modelo
\subsection{Validación del modelo}
Para el desarrollo de una RNA, es necesario dividir al conjunto de datos en dos subconjuntos: uno para el 
entrenamiento y otro para la validación o prueba. El conjunto de entrenamiento se emplea para entrenar a 
la red, mientras que el conjunto de prueba se utiliza para evaluar su desempeño. Es crucial asegurarse de 
que el conjunto de entrenamiento sea lo suficientemente grande para ser representativo del problema, mientras 
que el de prueba sea lo suficientemente grande para facilitar una correcta validación de la red. En casos 
donde el número de ejemplos disponible no es suficiente para realizar la división representativa, se 
pueden utilizar otras estrategias \citep{CITE:42}. 
El procedimiento mayormente empleado es la validación cruzada de $k$ 
iteraciones, también conocida como \emph{k-fold cross validation}, que se ilustra en la figura \ref{fig:crossval}. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./Figures/cross_validation.jpg}
	\caption{Representación esquemática de \emph{k-fold cross validation} con $k=5$\protect\footnotemark.}
	\label{fig:crossval}
\end{figure}


La validación cruzada de $k$ iteraciones consiste en dividir el conjunto de datos en $k$ subconjuntos. Durante 
el proceso de entrenamiento, se toma cada $k$ subconjunto como el conjunto de prueba, mientras que los 
restantes ($k-1$) se utilizan como conjunto de entrenamiento. Este proceso se repetie $k$ veces, donde 
en cada iteración se toma un conjunto de prueba diferente y los datos remanentes forman el conjunto 
de entrenamiento. Al finalizar las $k$ iteraciones, se calcula el promedio de las métricas y los errores 
obtenidos para cada subconjunto de prueba \citep{CITE:48}.

%----------------------------------------------------------------------------------------
% 2.3.5 Optimización del modelo
\filbreak
\subsection{Optimización del modelo}
Es fundamental comprender el papel de los optimizadores y su impacto en el entrenamiento de una red neuronal. 
Los optimizadores son algoritmos empleados para ajustar los parámetros de la red, con el fin de minimizar 
la función de pérdida. Como resultado, logran mejorar la capacidad de aprendizaje y rendimiento del modelo. 
Algunos optimizadores comúnmente utilizados incluyen: descenso de gradiente estocástico, AdaGrad, Adam y RMSprop. 
Cada uno de ellos posee sus propias características y métodos de actualización de parámetros. Por lo tanto, 
la elección del optimizador es un paso importante en el desarrollo de un modelo, ya que puede influir 
significativamente en la velocidad y calidad de convergencia durante el entrenamiento \citep{CITE:44}.

\footnotetext{Imagen adaptada de Ashfaque Maat, Johar y Iqbal, Amer. (2019). Introduction to Support Vector Machines and Kernel Methods.}

En particular, el algoritmo de optimización empleado en este trabajo fue propuesto por 
Diederik Kingma y Jimmy Ba en su artículo ``\emph{Adam: A Method for Stochastic Optimization}'' \citep{CITE:49}. Si bien 
la elección del optimizador depende de diversos factores, Adam se destaca por múltiples ventajas, que incluyen:

\begin{itemize}
	\item Implementación sencilla.
	\item Eficiencia computacional.
	\item Requisitos de memoria reducidos.
	\item Invarianza a la reescala diagonal de los gradientes.
	\item Adecuación para problemas con muchos datos y/o parámetros.
	\item Idoneidad para problemas con gradientes muy ruidosos o dispersos.
	\item Hiperparámetros con interpretación intuitiva que generalmente requieren poco ajuste.
\end{itemize}


%----------------------------------------------------------------------------------------
% 2.3.6 Hiperparámetros del modelo
\subsection{Hiperparámetros del modelo}
En los modelos de aprendizaje automático, los parámetros son las variables que se estiman durante el 
proceso de entrenamiento con el conjunto de datos. Por otro lado, los hiperparámetros del modelo 
corresponden a los valores de configuración que se emplean durante dicho proceso. A diferencia de 
los parámetros, los hiperparámetros no son afectados por el algoritmo de aprendizaje. Por lo tanto, 
deben ser establecidos antes del entrenamiento y se mantienen constantes durante el mismo \citep{CITE:44}.

Usualmente, gran parte del diseño de una RNA implica la selección y ajuste de los hiperparámetros. 
Una elección adecuada puede tener un impacto significativo en el desempeño del modelo, ya que estos 
determinan el comportamiento y la capacidad de aprendizaje de la red. Algunos hiperparámetros 
que pueden ser ajustados incluyen: cantidad y tipo de capas ocultas, cantidad de neuronas en cada capa,
función de activación, función de pérdida, optimizador, tasa de aprendizaje, tamaño del lote y
número de épocas de entrenamiento \citep{CITE:35} \citep{CITE:42} \citep{CITE:44}.


