\chapter{Introducción específica} % Main chapter title

\label{Chapter2}

%----------------------------------------------------------------------------------------
%	2.1 ENFOQUE DEL PROBLEMA
%----------------------------------------------------------------------------------------
ESCRIBIR PARRAFO INTRODUCTORIO

\section{Enfoque del problema}
\label{sec:Enfoque del problema}

El presente trabajo se estructura en torno a tres etapas principales, las cuales se 
encuentran ilustradas en la figura \ref{fig:Etapas de trabajo}.


\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./Figures/Etapas de trabajo.jpg}
	\caption{Representación esquemática de las etapas del trabajo.}\label{fig:Etapas de trabajo}
\end{figure}

Para comenzar, se llevó a cabo la adquisición de datos. 
Esta etapa fue realizada en colaboración con el servicio de cardiología del Hospital Alemán. 
Para ello, se recopiló información proveniente de presurometrías realizadas a pacientes 
hipertensos a partir del año 2013. Además, se efectuó un análisis exhaustivo de la historia 
clínica de cada paciente con el objetivo de identificar la ocurrencia de eventos cardiovasculares 
adversos mayores. De esta manera, se logró completar el \textit{dataset} con la variable a predecir (MACE) 
para cada paciente. Asimismo, se enriqueció el conjunto de datos con información clínica adicional 
con el fin de contar con variables explicativas más amplias para abordar el problema de investigación.

A continuación, se efectuó una etapa de preprocesamiento. En primer lugar, se procedió a realizar 
una limpieza de los datos con el propósito de seleccionar las variables más representativas del 
problema. Este proceso de selección permitió eliminar datos redundantes, ruidosos o de poca 
utilidad para el análisis posterior. También, se realizó un análisis exploratorio de datos 
para comprender de manera más profunda las características y patrones presentes en el \textit{dataset}. 
Esto proporcionó una visión más completa y significativa del conjunto de datos, permitiendo 
así una mejor comprensión de la naturaleza del problema y orientando la toma de decisiones 
posteriores en el desarrollo de este trabajo.

Por último, se procedió al diseñó y entrenamiento de dos modelos de clasificación utilizando 
redes neuronales. El primer modelo se construyó exclusivamente con los datos de presurometrías, 
mientras que el segundo modelo se enriqueció al incluir también los datos clínicos. El propósito 
de esta estrategia fue analizar y comparar el rendimiento de los dos modelos y evaluar si los 
datos de MAPA tienen un sustento suficiente para predecir la variable objetivo MACE. De esta 
manera, se buscó determinar si la inclusión de información clínica adicional contribuyó a 
mejorar las métricas de desempeño en la predicción de MACE, y si podría tener implicancias 
clínicas relevantes para el seguimiento de los pacientes.

%----------------------------------------------------------------------------------------
%	2.2 ALGORITMOS DE CLASIFICACION
%----------------------------------------------------------------------------------------
\section{Algoritmos de clasificación}
\label{sec:Algoritmos de clasificación}

ESCRIBIR PARRAFO INTRODUCTORIO

\subsection{Fundamentos de los modelos de clasificación}
Un algoritmo de aprendizaje automático es una herramienta que permite resolver tareas  
que suelen ser complejas de abordar para los seres humanos. La principal ventaja del \emph{machine 
learning} (ML) es su capacidad de aprender de los datos y extraer información relevante de 
estos. Las tareas de ML se describen en términos de cómo deben procesar un ejemplo, que se 
compone de una colección de características cuantitativas o \emph{features} que se miden de un objeto 
o evento que se desea procesar. En general, se representa un ejemplo como un vector $ x\in\mathbb{R}^n $,
donde cada entrada $x_{i}$ del vector corresponde a una característica del objeto 
o evento en cuestión. De esta manera, el algoritmo de aprendizaje de máquina es capaz de 
analizar los datos y extraer patrones que permiten tomar decisiones o realizar predicciones 
precisas \citep{CITE:35}.

En el campo del aprendizaje automático, los modelos de clasificación desempeñan un papel fundamental 
\citep{CITE:32}. Estos modelos se encargan de asignar etiquetas discretas o categorías a ejemplos 
específicos según sus características \citep{CITE:33}. Dependiendo del enfoque utilizado durante el 
entrenamiento, los modelos pueden ser de dos tipos: supervisados o no supervisados \citep{CITE:35}.

En un modelo de clasificación no supervisado, las etiquetas no se proporcionan en el conjunto de 
datos de entrenamiento \citep{CITE:34}. En lugar de ello, el algoritmo busca patrones y estructuras 
en los datos sin la guía explícita de las etiquetas. Como resultado, el objetivo es agrupar las instancias en 
clases basadas en similitudes \citep{CITE:33}.

Por otro lado, en un modelo de clasificación supervisado se proporciona al algoritmo un \emph{dataset} de 
entrenamiento que incluye tanto las características de las instancias como las etiquetas correspondientes 
\citep{CITE:33}. El modelo utiliza esta información para aprender a asociar las \emph{features} con las 
etiquetas, lo que le permite clasificar nuevas instancias de manera precisa. Algunos ejemplos de algoritmos 
supervisados ampliamente utilizados son los árboles de decisión, las máquinas de vectores de soporte y 
las redes neuronales \citep{CITE:34}. En este trabajo en particular, se empleó un modelo de clasificación 
supervisado basado en redes neuronales con el propósito de predecir MACE.

\subsection{Estrategias para tratar el desbalance de clases}

Un conjunto de datos se considera desbalanceado cuando presenta una proporción significativamente mayor 
de observaciones pertenecientes a una clase en comparación con la otra. Este desequilibrio puede tener 
un impacto considerable en el rendimiento de los modelos de aprendizaje automático. En el caso específico 
de una red neuronal entrenada con un \emph{dataset} desbalanceado, es probable que encuentre dificultades 
para discriminar de manera adecuada entre las diferentes clases. En otras palabras, el desequilibrio de 
clases crea un sesgo en el cual el modelo tiende a predecir la clase mayoritaria, lo que dificulta la 
correcta clasificación de los ejemplos pertenecientes a la clase minoritaria \citep{CITE:36} \citep{CITE:37}. 

Abordar el desequilibrio se convierte en un desafío crucial en la tarea de modelado y actualmente existen 
dos enfoques principales. El primero consiste en asignar diferentes pesos a los ejemplos de entrenamiento, 
mientras que el segundo implica realizar un remuestreo del conjunto de datos original. Es posible crear 
un nuevo muestreo del \emph{dataset} efectuando un sobremuestreo de la clase minoritaria y/o un submuestreo 
de la clase mayoritaria. El submuestreo implica una reducción del número de instancias de la clase mayoritaria, 
lo cual puede resultar en la pérdida de información valiosa que sea representativa de la distribución de los 
datos. Por otra parte, el sobremuestreo suele implicar réplicas de ejemplos de la clase minoritaria, lo cual 
puede generar un sobreajuste. En concreto, el modelo concede predicciones muy precisas para el conjunto de 
entrenamiento pero no logra generalizar adecuadamente cuando se presentan nuevos datos \citep{CITE:37}. 

Para mitigar las desventajas mencionadas anteriormente, Nitesh Chawla \emph{et al.} \citep{CITE:37} 
introducen una nueva técnica que implica una forma especial 
de sobremuestrear la clase minoritaria. El algoritmo 
\emph{Synthetic Minority Over-sampling Technique} (SMOTE) implica la creación de muestras sintéticas de 
la clase minoritaria. Se expone una representación gráfica del algoritmo en la figura \ref{fig:SMOTE}. 
En primer lugar, el método escoge un ejemplo de la clase minoritaria al azar y encuentra a sus $k$ vecinos 
más cercanos. Luego, se selecciona uno de los $k$ vecinos más cercanos y se crea una conexión mediante 
un segmento de línea en el espacio de características con la muestra elegida al azar. Finalmente, se crea 
una instancia sintética en un punto aleatorio entre los dos ejemplos \citep{CITE:38}. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./Figures/SMOTE.jpg}
	\caption{Representación esquematica del algoritmo SMOTE.}\label{fig:SMOTE}
\end{figure}

En suma, SMOTE permite generar ejemplos sintéticos que sean relativamente cercanos en el espacio de 
características con respecto a las muestras existentes de la clase minoritaria. Además, las muestras 
pueden crearse en la cantidad que sea requerida. Por lo tanto, en escenarios donde el conjunto de 
datos no solo está desbalanceado sino que también presenta una escasez de muestras, la aplicación 
de SMOTE resulta particularmente efectiva \citep{CITE:37} \citep{CITE:38}.



\subsection{Métricas de evaluación en modelos de clasificación}
